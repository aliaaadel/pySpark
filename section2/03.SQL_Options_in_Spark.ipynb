{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Options in Spark\n",
    "\n",
    "PySpark provides two main options when it comes to using staight SQL. Spark SQL and SQL Transformer. \n",
    "\n",
    "## 1. Spark SQL\n",
    "\n",
    "Spark TempView provides two functions that allow users to run **SQL** queries against a Spark DataFrame: \n",
    "\n",
    " - **createOrReplaceTempView:** The lifetime of this temporary view is tied to the SparkSession that was used to create the dataset. It creates (or replaces if that view name already exists) a lazily evaluated \"view\" that you can then use like a hive table in Spark SQL. It does not persist to memory unless you cache the dataset that underpins the view.\n",
    " - **createGlobalTempView:** The lifetime of this temporary view is tied to this Spark application. This feature is useful when you want to share data among different sessions and keep alive until your application ends.\n",
    "     - Why we could need it? \n",
    "         - The first obvious use case - when we need to use data coming from different SparkSessions which can't share the same configuration. The configuration can concern for instance 2 different Hive metastores and their data that somehow must be mixed together.\n",
    "         - We can launch 2 different independent Spark jobs from one common code. Using an orchestration tool seems a better idea though because in the case of the second's session failure, you'll need only to relaunch it without needing to recompute the first dataset.\n",
    "         - We could use multiple SparkSessions is the case when some external input defines the number of jobs not sharing the same configuration to launch\n",
    "\n",
    "A **Spark Session vs. Spark application:**\n",
    "\n",
    "**Spark application** can be used:\n",
    "\n",
    "- for a single batch job\n",
    "- an interactive session with multiple jobs\n",
    "- a long-lived server continually satisfying requests\n",
    "- A Spark job can consist of more than just a single map and reduce.\n",
    "- can consist of more than one Spark Session. \n",
    "\n",
    "A **SparkSession** on the other hand:\n",
    "\n",
    " - is an interaction between two or more entities. \n",
    " - can be created without creating SparkConf, SparkContext or SQLContext, (theyâ€™re encapsulated within the SparkSession which is new to Spark 2.0)\n",
    "\n",
    "\n",
    "## 2. SQL Transformer\n",
    "\n",
    "You also have the option to use the SQL transformer option where you can write free-form SQL scripts as well.\n",
    "\n",
    "# SQL Options within regular PySpark calls\n",
    "\n",
    "1. The expr function in PySparks SQL Function Library\n",
    "2. PySparks selectExpr function\n",
    "\n",
    "We will go over all these in detail so buckel up!\n",
    "\n",
    "\n",
    "Let's start with Spark SQL. But first we need to create a Spark Session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are working with 1 core(s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://5ffde657c666:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkSQL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb9768a20e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "# May take awhile locally\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
    "\n",
    "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
    "print(\"You are working with\", cores, \"core(s)\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Read in our DataFrame for this Notebook\n",
    "\n",
    "### About this data\n",
    "\n",
    "Recorded crime for the Police Force Areas of England and Wales. The data are rolling 12-month totals, with points at the end of each financial year between year ending March 2003 to March 2007 and at the end of each quarter from June 2007.\n",
    "\n",
    "**Source:** https://www.kaggle.com/r3w0p4/recorded-crime-data-at-police-force-area-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by reading a basic csv dataset\n",
    "# Let Spark know about the header and infer the Schema types!\n",
    "\n",
    "path = 'Datasets/'\n",
    "\n",
    "crime = spark.read.csv(path+\"rec-crime-pfa.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12 months ending</th>\n",
       "      <th>PFA</th>\n",
       "      <th>Region</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Rolling year total number of offences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>All other theft offences</td>\n",
       "      <td>25959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Bicycle theft</td>\n",
       "      <td>3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Criminal damage and arson</td>\n",
       "      <td>26202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Death or serious injury caused by illegal driving</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Domestic burglary</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  12 months ending                PFA      Region  \\\n",
       "0       31/03/2003  Avon and Somerset  South West   \n",
       "1       31/03/2003  Avon and Somerset  South West   \n",
       "2       31/03/2003  Avon and Somerset  South West   \n",
       "3       31/03/2003  Avon and Somerset  South West   \n",
       "4       31/03/2003  Avon and Somerset  South West   \n",
       "\n",
       "                                             Offence  \\\n",
       "0                           All other theft offences   \n",
       "1                                      Bicycle theft   \n",
       "2                          Criminal damage and arson   \n",
       "3  Death or serious injury caused by illegal driving   \n",
       "4                                  Domestic burglary   \n",
       "\n",
       "   Rolling year total number of offences  \n",
       "0                                  25959  \n",
       "1                                   3090  \n",
       "2                                  26202  \n",
       "3                                      2  \n",
       "4                                  14561  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is way better\n",
    "crime.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 12 months ending: string (nullable = true)\n",
      " |-- PFA: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Offence: string (nullable = true)\n",
      " |-- Rolling year total number of offences: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(crime.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in order for us to perform SQL calls off of this dataframe, we will need to rename any variables that have spaces in them. We will not be using the first variable so I'll leave that one as is, but we will be using the last variable, so I will go ahead and change that to Count so we can work with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 12 months ending: string (nullable = true)\n",
      " |-- PFA: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Offence: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = crime.withColumnRenamed('Rolling year total number of offences','Count') #.withColumn(\"12 months ending\", crime[\"12 months ending\"].cast(DateType())).\n",
    "print(df.printSchema()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view of the dataframe\n",
    "df.createOrReplaceTempView(\"tempview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12 months ending</th>\n",
       "      <th>PFA</th>\n",
       "      <th>Region</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>All other theft offences</td>\n",
       "      <td>25959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Bicycle theft</td>\n",
       "      <td>3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Criminal damage and arson</td>\n",
       "      <td>26202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Domestic burglary</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Drug offences</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  12 months ending                PFA      Region                    Offence  \\\n",
       "0       31/03/2003  Avon and Somerset  South West   All other theft offences   \n",
       "1       31/03/2003  Avon and Somerset  South West              Bicycle theft   \n",
       "2       31/03/2003  Avon and Somerset  South West  Criminal damage and arson   \n",
       "3       31/03/2003  Avon and Somerset  South West          Domestic burglary   \n",
       "4       31/03/2003  Avon and Somerset  South West              Drug offences   \n",
       "\n",
       "   Count  \n",
       "0  25959  \n",
       "1   3090  \n",
       "2  26202  \n",
       "3  14561  \n",
       "4   2308  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then Query the temp view\n",
    "spark.sql(\"SELECT * FROM tempview WHERE Count > 1000 limit 10\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>PFA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South West</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Region                PFA\n",
       "0  South West  Avon and Somerset\n",
       "1  South West  Avon and Somerset\n",
       "2  South West  Avon and Somerset\n",
       "3  South West  Avon and Somerset\n",
       "4  South West  Avon and Somerset"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or choose which vars you want\n",
    "spark.sql(\"SELECT Region, PFA FROM tempview WHERE Count > 1000\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12 months ending</th>\n",
       "      <th>PFA</th>\n",
       "      <th>Region</th>\n",
       "      <th>Offence</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>All other theft offences</td>\n",
       "      <td>25959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Bicycle theft</td>\n",
       "      <td>3090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Criminal damage and arson</td>\n",
       "      <td>26202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Domestic burglary</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2003</td>\n",
       "      <td>Avon and Somerset</td>\n",
       "      <td>South West</td>\n",
       "      <td>Drug offences</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  12 months ending                PFA      Region                    Offence  \\\n",
       "0       31/03/2003  Avon and Somerset  South West   All other theft offences   \n",
       "1       31/03/2003  Avon and Somerset  South West              Bicycle theft   \n",
       "2       31/03/2003  Avon and Somerset  South West  Criminal damage and arson   \n",
       "3       31/03/2003  Avon and Somerset  South West          Domestic burglary   \n",
       "4       31/03/2003  Avon and Somerset  South West              Drug offences   \n",
       "\n",
       "   Count  \n",
       "0  25959  \n",
       "1   3090  \n",
       "2  26202  \n",
       "3  14561  \n",
       "4   2308  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also pass your query results to an object \n",
    "# (we don't need to use .collect() here)\n",
    "sql_results = spark.sql(\"SELECT * FROM tempview WHERE Count > 1000 AND Region='South West'\")\n",
    "sql_results.limit(5).toPandas()\n",
    "# type(sql_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fraud: CIFAS</td>\n",
       "      <td>7678981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North West</td>\n",
       "      <td>30235732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>British Transport Police</td>\n",
       "      <td>3029117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wales</td>\n",
       "      <td>11137260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>42691902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Region     Total\n",
       "0              Fraud: CIFAS   7678981\n",
       "1                North West  30235732\n",
       "2  British Transport Police   3029117\n",
       "3                     Wales  11137260\n",
       "4                    London  42691902"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even do aggregated \"group by\" calls like this\n",
    "spark.sql(\"SELECT Region, sum(Count) AS Total FROM tempview GROUP BY Region\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basically anything goes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus!** <br>\n",
    "Not included in the lecture, but thought some of you may enjoy this. If you want to write more freeform style SQL you can enclose your query in triple quotes like this. Here I have shown an example using CTE which a more advanced SQL procedure. A common table expression (CTE) defines a temporary result set that a user can reference possibly multiple times within the scope of a SQL statement. A CTE is used mainly in a SELECT statement. Many people find this super useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0  1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could also do more complex SQL queries like CTE (not included )\n",
    "spark.sql(\"\"\"WITH t AS (\n",
    "    WITH tempview AS (SELECT 1)\n",
    "    SELECT * FROM tempview\n",
    ")\n",
    "SELECT * FROM t;\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Transformer\n",
    "\n",
    "You also have the option to use the SQL transformer option where you can write freeform SQL scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to import SQL transformer\n",
    "from pyspark.ml.feature import SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+--------------------+\n",
      "|              PFA|    Region|             Offence|\n",
      "+-----------------+----------+--------------------+\n",
      "|Avon and Somerset|South West|All other theft o...|\n",
      "|Avon and Somerset|South West|       Bicycle theft|\n",
      "|Avon and Somerset|South West|Criminal damage a...|\n",
      "|Avon and Somerset|South West|Death or serious ...|\n",
      "|Avon and Somerset|South West|   Domestic burglary|\n",
      "+-----------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Then we create an SQL call \n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT PFA,Region,Offence FROM __THIS__\") \n",
    "# And use it to transform our df object\n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.SQLTransformer"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sqlTrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: __THAT__; line 1 pos 31;\n'Project ['PFA, 'Region, 'Offence]\n+- 'UnresolvedRelation [__THAT__], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m sqlTrans \u001b[38;5;241m=\u001b[39m SQLTransformer(\n\u001b[1;32m      3\u001b[0m     statement\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT PFA,Region,Offence FROM __THAT__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# And use it to transform our df object\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43msqlTrans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py:400\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: __THAT__; line 1 pos 31;\n'Project ['PFA, 'Region, 'Offence]\n+- 'UnresolvedRelation [__THAT__], [], false\n"
     ]
    }
   ],
   "source": [
    "# Note that \"__THIS__\" is a special word and cannot be change to __THAT__ for example\n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT PFA,Region,Offence FROM __THAT__\") \n",
    "# And use it to transform our df object\n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SQLTransformer' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1ccfb6779f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mSQLTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SELECT PFA,Region,Offence FROM __THIS__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SQLTransformer' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "# Also Note that a call like this won't work...\n",
    "SQLTransformer(statement=\"SELECT PFA,Region,Offence FROM __THIS__\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now how about a group by call**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|             Offence|   Total|\n",
      "+--------------------+--------+\n",
      "|Public order offe...|10925676|\n",
      "|       Bicycle theft| 5297006|\n",
      "|Residential burglary| 1671469|\n",
      "|Violence without ...|16590158|\n",
      "|All other theft o...|30979393|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Note that this call will not work on the original dataframe \"crime\" when the variable \"Count\" is a string\n",
    "\n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT Offence, SUM(Count) as Total FROM __THIS__ GROUP BY Offence\") \n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And a where statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|              PFA|             Offence|\n",
      "+-----------------+--------------------+\n",
      "|Avon and Somerset|All other theft o...|\n",
      "|Avon and Somerset|       Bicycle theft|\n",
      "|Avon and Somerset|Criminal damage a...|\n",
      "|Avon and Somerset|   Domestic burglary|\n",
      "|Avon and Somerset|       Drug offences|\n",
      "+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT PFA,Offence FROM __THIS__ WHERE Count > 1000\") \n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can also, of course, read the output into a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|              PFA|             Offence|\n",
      "+-----------------+--------------------+\n",
      "|Avon and Somerset|All other theft o...|\n",
      "|Avon and Somerset|       Bicycle theft|\n",
      "|Avon and Somerset|Criminal damage a...|\n",
      "|Avon and Somerset|   Domestic burglary|\n",
      "|Avon and Somerset|       Drug offences|\n",
      "+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = sqlTrans.transform(df)\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Options within regular PySpark calls\n",
    "\n",
    "### The expr function in PySparks SQL Function Library\n",
    "\n",
    "You can also use the expr function within the pyspark.sql.functions library coupled with either PySpark's withColumn function or the select function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to read in the library\n",
    "from pyspark.sql.functions import expr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a percent column to the dataframe. To do this, first we need to get the total number of rows in the dataframe (we can't soft this unfortunatly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|    Total|\n",
      "+---------+\n",
      "|244720928|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT SUM(Count) as Total FROM __THIS__\") \n",
    "sqlTrans.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|percent|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Death or serious ...|    2|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|            Homicide|   19|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Possession of wea...|  735|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Stalking and hara...|  740|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|   0.02|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|    0.0|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We could add a percent column to our df \n",
    "# that shows the offence %\n",
    "# with the \"withColumn\" command\n",
    "df.withColumn(\"percent\",expr(\"round((count/244720928)*100,2)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|percent|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Death or serious ...|    2|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|            Homicide|   19|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Possession of wea...|  735|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Stalking and hara...|  740|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|   0.02|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|    0.0|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same thing with the \"select\" command\n",
    "df.select(\"*\",expr(\"round((count/244720928)*100,2) AS percent\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySparks selectExpr function\n",
    "\n",
    "Very similar idea here but slightly different syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|percent|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Death or serious ...|    2|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|            Homicide|   19|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|   0.01|\n",
      "|      31/03/2003|Avon and Somerset|South West|Possession of wea...|  735|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Stalking and hara...|  740|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|   0.02|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|    0.0|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|    0.0|\n",
      "+----------------+-----------------+----------+--------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"*\",\"round((count/244720928)*100,2) AS percent\").filter(\"Region ='South West'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's all folks! Great job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|\n",
      "|      31/03/2003|     Bedfordshire|      East|All other theft o...| 8797|\n",
      "|      31/03/2003|     Bedfordshire|      East|Criminal damage a...|10006|\n",
      "|      31/03/2003|     Bedfordshire|      East|   Domestic burglary| 3784|\n",
      "|      31/03/2003|     Bedfordshire|      East|       Drug offences| 1069|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15072178840637207"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = time.time()\n",
    "spark.sql(\"SELECT * FROM tempview WHERE Count > 1000\").show()\n",
    "after = time.time()\n",
    "after - before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|\n",
      "|      31/03/2003|     Bedfordshire|      East|All other theft o...| 8797|\n",
      "|      31/03/2003|     Bedfordshire|      East|Criminal damage a...|10006|\n",
      "|      31/03/2003|     Bedfordshire|      East|   Domestic burglary| 3784|\n",
      "|      31/03/2003|     Bedfordshire|      East|       Drug offences| 1069|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14869451522827148"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = time.time()\n",
    "# Then we create an SQL call \n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT * FROM __THIS__ WHERE Count > 1000\")\n",
    "# And use it to transform our df object\n",
    "sqlTrans.transform(df).show()\n",
    "after = time.time()\n",
    "after - before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|12 months ending|              PFA|    Region|             Offence|Count|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "|      31/03/2003|Avon and Somerset|South West|All other theft o...|25959|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Bicycle theft| 3090|\n",
      "|      31/03/2003|Avon and Somerset|South West|Criminal damage a...|26202|\n",
      "|      31/03/2003|Avon and Somerset|South West|   Domestic burglary|14561|\n",
      "|      31/03/2003|Avon and Somerset|South West|       Drug offences| 2308|\n",
      "|      31/03/2003|Avon and Somerset|South West|      Fraud offences| 5339|\n",
      "|      31/03/2003|Avon and Somerset|South West|Miscellaneous cri...| 1597|\n",
      "|      31/03/2003|Avon and Somerset|South West|Non-domestic burg...|15621|\n",
      "|      31/03/2003|Avon and Somerset|South West|Public order offe...| 4025|\n",
      "|      31/03/2003|Avon and Somerset|South West|             Robbery| 3504|\n",
      "|      31/03/2003|Avon and Somerset|South West|     Sexual offences| 1737|\n",
      "|      31/03/2003|Avon and Somerset|South West|         Shoplifting| 8410|\n",
      "|      31/03/2003|Avon and Somerset|South West|Theft from the pe...| 2554|\n",
      "|      31/03/2003|Avon and Somerset|South West|    Vehicle offences|41781|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence with injury| 8565|\n",
      "|      31/03/2003|Avon and Somerset|South West|Violence without ...| 7117|\n",
      "|      31/03/2003|     Bedfordshire|      East|All other theft o...| 8797|\n",
      "|      31/03/2003|     Bedfordshire|      East|Criminal damage a...|10006|\n",
      "|      31/03/2003|     Bedfordshire|      East|   Domestic burglary| 3784|\n",
      "|      31/03/2003|     Bedfordshire|      East|       Drug offences| 1069|\n",
      "+----------------+-----------------+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1356346607208252"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = time.time()\n",
    "# Then we create an SQL call \n",
    "df.filter(\"Count > 1000\").show()\n",
    "#SQLTransformer(statement=\"SELECT * FROM __THIS__ WHERE Count > 1000\").transform(df).show()\n",
    "after = time.time()\n",
    "after - before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
